[{"content":"简介 最近一段时间，除了毕设就没有别的什么事情了，于是开始看起了鼎鼎大名的MIT（麻省理工学院）6.S081操作系统课程（实际是三天打鱼两天晒网\u0026hellip;之前沉迷于战地1无法自拔）\n对于操作系统这门课程，我之前只是自己看书自学了一遍，有很多知识都是一知半解，并没有深入了解其中的原理。这次也算是用这个课程来恶补一下我的基础吧。感谢MIT网课的两位教授，从课堂中我学到了很多很多东西，虽然网课总共只看了1/3，但也可以称得上受益匪浅了。\n环境配置  本人的配置：Ubuntu 20.04 WSL2\n 根据官网上的教程配置即可\n注意开启GDB的方式可能和网课上讲的不太一样，查阅资料后发现步骤应该是：\n# 在xv6文件夹中 gdb-multiarch kernel/kernel # 进入GDB后 set architecture riscv:rv64 target remote localhost:26000 代码详解 这个实验相对还是比较简单的，主要是起了热身的作用吧。除了prime，其他任务都很快就完成了。\nsleep // user/sleep.c  void Error_Handler() { fprintf(2, \u0026#34;Usage: sleep [time]\\n\u0026#34;); exit(1); } int main(int argc, char const *argv[]) { if (argc != 2) { Error_Handler(); } int time = 0; if ((time = atoi(argv[1])) == 0) { Error_Handler(); } sleep(time); exit(0); } pingpong // user/pingpong.c  #include \u0026#34;kernel/types.h\u0026#34;#include \u0026#34;user/user.h\u0026#34;#include \u0026#34;kernel/fcntl.h\u0026#34; int main() { int p[2]; pipe(p); if (fork() == 0) { close(p[1]); char buf[5]; read(p[0], buf, 4); fprintf(1, \u0026#34;%d: received ping\\n\u0026#34;, getpid()); close(p[0]); exit(0); } else { close(p[0]); write(p[1], \u0026#34;test\u0026#34;, 4); close(p[1]); wait(0); fprintf(2, \u0026#34;%d: received pong\\n\u0026#34;, getpid()); exit(0); } } 前面两个都没什么好说的\u0026hellip;\nprimes #include \u0026#34;kernel/types.h\u0026#34;#include \u0026#34;user/user.h\u0026#34;#include \u0026#34;kernel/fcntl.h\u0026#34; int primes[11] = {2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31}; void prime_sieve(int *data_pipe, int n) { // 注意此处一定要关闭前管道的写端，不然会无法退出子进程！  close(data_pipe[1]); if (n \u0026gt; 10) { exit(0); } int inner_p[2]; pipe(inner_p); if (fork() == 0) { prime_sieve(inner_p, n + 1); } else { close(inner_p[0]); int num; read(data_pipe[0], \u0026amp;num, 4); printf(\u0026#34;prime %d\\n\u0026#34;, num); while (read(data_pipe[0], \u0026amp;num, 4) != 0) { if (num % primes[n] != 0) { write(inner_p[1], \u0026amp;num, 4); } } close(data_pipe[0]); close(inner_p[1]); wait(0); exit(0); } } int main() { int p[2]; pipe(p); if (fork() == 0) { prime_sieve(p, 0); } else { close(p[0]); int i; for (i = 2; i \u0026lt;= 35; i++) { write(p[1], \u0026amp;i, 4); } close(p[1]); wait(0); } exit(0); } 这个task还是有点难度的，想出解决的思路不难，但很容易出bug，光debug就花了我三四个小时\u0026hellip;\n大坑是在创建子进程后，必须先把之前管道的写端给关掉，如果不关掉的话，后面继续fork子进程时，会把之前残留的这个管道写端又复制到子进程，导致子进程会有多个写端，则子进程会不断地等待写入，造成死循环，所有子进程都无法正确关闭。\n这个bug隐藏地太深，也许也是我技术太菜的原因，我花了非常多的时间才发现了这个bug，不得不说是个大坑\nfind #include \u0026#34;kernel/types.h\u0026#34;#include \u0026#34;kernel/stat.h\u0026#34;#include \u0026#34;user/user.h\u0026#34;#include \u0026#34;kernel/fs.h\u0026#34; void find(char *path, char *name) { int fd; struct stat st; struct dirent de; char buf[512], *p; if ((fd = open(path, 0)) \u0026lt; 0) { fprintf(2, \u0026#34;find: cannot open %s\\n\u0026#34;, path); return; } if (fstat(fd, \u0026amp;st) \u0026lt; 0) { fprintf(2, \u0026#34;find: cannot stat %s\\n\u0026#34;, path); close(fd); return; } strcpy(buf, path); p = buf + strlen(buf); *p++ = \u0026#39;/\u0026#39;; while (read(fd, \u0026amp;de, sizeof(de)) == sizeof(de)) { if (de.inum == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; if (strcmp(de.name, name) == 0) { printf(\u0026#34;%s\\n\u0026#34;, buf); } if (stat(buf, \u0026amp;st) \u0026lt; 0) { fprintf(3, \u0026#34;find: cannot stat %s\\n\u0026#34;, buf); continue; } if (st.type == T_DIR \u0026amp;\u0026amp; strcmp(\u0026#34;.\u0026#34;, de.name) != 0 \u0026amp;\u0026amp; strcmp(\u0026#34;..\u0026#34;, de.name) != 0) { find(buf, name); } } close(fd); } int main(int argc, char *argv[]) { find(argv[1], argv[2]); exit(0); } 这个task内容也算是比较简单的，比较麻烦的部分在于要参考其他程序中对于文件系统的处理方式，稍花一点时间就可以完全搬过来了\nxargs #include \u0026#34;kernel/types.h\u0026#34;#include \u0026#34;kernel/stat.h\u0026#34;#include \u0026#34;kernel/param.h\u0026#34;#include \u0026#34;user/user.h\u0026#34;#include \u0026#34;kernel/fs.h\u0026#34; int main(int argc, char *argv[]) { // 构造参数列表  char **args = (char **)malloc(MAXARG * sizeof(char *)); int i; for (i = 0; i \u0026lt; argc - 1; i++) { args[i] = malloc(strlen(argv[i + 1]) + 1); strcpy(args[i], argv[i + 1]); } int command_i = i; char ch; char buf[50]; i = 0; while (read(0, \u0026amp;ch, 1) != 0) { if (ch == \u0026#39;\\n\u0026#39;) { buf[i] = 0; args[command_i] = (char *)malloc(strlen(buf) + 1); strcpy(args[command_i], buf); memset(buf, 0, 50); i = 0; if (fork() == 0) { exec(args[0], args); } else { wait(0); int j; for (j = 1; j \u0026lt;= command_i; j++) { free(args[j]); } free(args); // 重新构造参数列表  args = (char **)malloc(MAXARG * sizeof(char *)); int i; for (i = 0; i \u0026lt; argc - 1; i++) { args[i] = malloc(strlen(argv[i + 1]) + 1); strcpy(args[i], argv[i + 1]); } command_i = i; } } else if (ch == \u0026#39; \u0026#39;) { buf[i] = 0; args[command_i] = (char *)malloc(strlen(buf) + 1); strcpy(args[command_i], buf); memset(buf, 0, 50); command_i++; i = 0; } else { buf[i++] = ch; } } exit(0); } 由于做这个实验已经过了很久，对这个task的印象不是很深了，我记得我当初是读错了题目要求，所以刚开始怎么都无法解决。后面重新审了题，再加上参考了网上一些大佬的程序，最终还是完成了，总体而言确实是moderate的难度。\n总结 对于OS基础薄弱的我来说，这个课程和配套的Lab确实教会了我很多，不光是概念上的知识，也有实际动手的经验。在Lab中，很多晦涩难懂、抽象的东西都变成了实实在在的代码，在将每个步骤拆解、拼装成程序后，自然地就将理论知识和实践融会贯通了。希望学完这门课之后，如果在面试中遇到操作系统原理相关的问题，我能够侃侃而谈，信心十足吧。\n感谢MIT，感谢互联网，让全球的每个学生都能享受顶级的计算机知识教育！\n（未完待续\u0026hellip;）\n","date":"2022-04-14T20:00:00+08:00","image":"https://cyderx.com/p/mit-6.s081-lab-1/bg_hu3d03a01dcc18bc5be0e67db3d8d209a6_616308_120x120_fill_q75_box_smart1.jpg","permalink":"https://cyderx.com/p/mit-6.s081-lab-1/","title":"MIT 6.S081 Lab 1"},{"content":"简介 大四的最后两周，连续爆肝做了两个课设，加上实验室的活，属实是把我累坏了。\n想不到我们的电子信息工程专业，竟然还有一个关于Android开发的课设项目，内容简单来讲就是跟着老师做一个简单的地图（使用百度地图的SDK）。老师手把手教学，要求也不高，水的不能再水了。\n但就是这么水的项目，我还是想把它认真做好的，因此爆肝了一个星期，恶补Android开发知识，总算勉强做出了一个能看的Demo项目。\nGithub地址：cyder-map\n技术栈  Material Components 百度地图Android SDK 简单的SQLite  实现功能  用户登陆与注册 地图展示 经纬度定位 城市定位 两点的公里数计算  实现效果 \r用户登陆界面\r\n\r用户注册界面\r\n\r地图显示界面\r\n\r城市定位功能\r\n\r经纬度定位功能\r\n","date":"2022-01-10T01:00:00+08:00","image":"https://cyderx.com/p/cyder-map/bg_hu3d03a01dcc18bc5be0e67db3d8d209a6_4331049_120x120_fill_q75_box_smart1.jpg","permalink":"https://cyderx.com/p/cyder-map/","title":"CyderMap——HHU仿百度地图课设项目"},{"content":"先挖个坑，还没更完，有时间再补充完整 :)\n底层数据结构 SDS 简单动态字符串（Simple Dynamic String）\n\rSDS的底层结构\r\n优点：\n 常数复杂度获取字符串长度 防止缓冲区溢出 减少修改字符串的内存重分配次数（空间预分配，小于1MB时分配和len同样大小的未使用空间，大于1MB时分配1MB的未使用空间） 二进制安全（可以包含空字符） 兼容部分C字符串函数  链表 \r链表的底层结构\r\n特点：\n 双端 无环 带表头指针和表尾指针 带链表长度计数器 多态  字典 \r字典的底层结构\r\n  dict（字典） -\u0026gt; dictht（dict hash table，也就是哈希表）-\u0026gt; dictEntry（哈希表节点）\n  一般字典只使用ht[0]哈希表，ht[1]只会在扩容时使用\n  rehashidx记录rehash目前的进度，如果没有在进行rehash，则值为-1\n  Redis使用MurmurHash2算法计算hash值\n在使用链表解决哈希冲突问题时，Redis把新加入的节点放在链表的表头位置，从而加快查找速度\nrehash   为ht[1]分配空间，大小取决于ht[0]的键值对数量\n  扩容：ht[1]的大小为第一个大于等于ht[0].used * 2的2^n\n  收缩：ht[1]的大小为第一个大于等于ht[0].used的2^n\n    重新计算索引值，移动元素\n  释放ht[0]，ht[1]变为ht[0]，ht[1]创建一个空表\n  采用渐进式rehash，将计算工作均摊到对字典的每个增删改查操作上\n扩容条件：\n 没在执行BGSAVE或BGWRITEAOF命令，且负载因子大于等于1 正在执行BGSAVE或BGWRITEAOF命令，且负载因子大于等于5  负载因子阈值不同的原因：Redis执行这些备份命令时，创建了一个子进程，使用写时复制技术来优化效率，此时应该避免向内存中写入新的数据（写入数据会在内存中创建新的页，造成性能开销），因此将负载因子阈值调高，防止触发扩容进行大量的写操作\n收缩条件：负载因子小于0.1\n跳表 平均O(logN)，最坏O(N)\n\r跳表的底层结构\r\n跳跃表节点的结构\n level[]（层数组），其中包含的元素：  前进指针（下一个节点的指针） 跨度（下一个节点和此节点的距离）   backward（后退指针）：用于从尾部向前遍历 score（分值）：（用于排序） obj：成员对象：指向字符串对象，它保存着一个SDS  层 创建新跳表节点时，根据幂次定律（power law，越大的数出现概率越小），随机生成一个介于1-32之间的值作为level数组的大小，这个大小就是层的高度\n整数集合 整数集合（intset）是保存整数的集合抽象数据类型，各个项在数组中按值的大小从小到大排序\n\r整数集合的底层结构\r\n升级 如果添加的元素类型比现有的元素类型长，则需要先进行升级（upgrade）\n步骤：\n 扩展数组空间大小 将现有元素全部转换为新类型的大小，并放至在正确的位上，保证有序性质 插入新元素  因为可能需要升级，所以添加的时间复杂度是O(N)\n只要升级，就不会降级，没有降级机制\n优点：\n 提升灵活性 节约内存  压缩列表 压缩列表（ziplist）是Redis为了节约内存开发的，由一系列特殊编码的连续内存块组成的顺序型数据结构\n一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或一个整数值\n\r压缩列表的底层结构(1)\r\n\r压缩列表的底层结构(2)\r\n压缩列表节点 每个压缩列表可以保存一个字节数组或一个整数值\n字节数组是以下三种长度的其中一种：\n\r字节数组的长度限定\r\n整数值是以下六种长度的其中一种：\n\r整数类型的限定\r\n节点结构：\n\r\nprevious_entry_length 长度可以是1字节或5字节，记录了前一个节点的长度\n 如果前一个节点长度小于254字节，则此属性长度为1字节，直接保存长度 如果前一个节点长度大于等于254字节，则为5字节，第一字节会被设为0xFE，后四个字节保存长度  可以使用此属性从表尾向表头遍历列表\nencoding 保存了数据类型和长度，将两部分保存在一起，起到了压缩空间的作用\n\r编码的规则\r\ncontent 保存节点的值\n连锁更新 节点的增加或删除，会引起previous_entry_length属性的连锁更新\n底层对象 一种对象可以利用几种数据结构储存对应的数据，需要根据情况来选择\n当在Redis中新建键值对时，我们至少创建了两个对象：键对象和值对象\n每个对象都由一个redisObject结构表示\n\r对象的底层结构(1)\r\n\r对象的底层结构(2)\r\n类型 五种类型：\n 字符串对象 列表对象 哈希对象 集合对象 有序集合对象  对于Redis键值对来说：\n 键：总是一个字符串对象 值：可以是五种类型中的一种  可以使用TYPE操作查看对象的类型\n编码 对象实际使用的数据类型由编码决定，也就是redisObject中的encoding属性\n\r编码常量和数据结构的对应关系\r\n可以使用OBJECT ENCODING操作查看对象的编码\nRedis中对象类型和底层数据结构的关系：\n\r对象类型和底层数据结构的关系(1)\r\n\r对象类型和底层数据结构的关系(2)\r\n注意：有序集合（zset）的跳跃表实现中，同时使用了跳跃表和字典！\n原因：\n 跳跃表按顺序遍历很方便，但查找元素对应的分值不方便，需要O(logN) 字典查找元素对应的分值方便，为O(1)，但无法做到按顺序遍历  因此有序集合就将它们一起结合使用了，需要查找分值的时候使用字典；需要按顺序遍历或者范围查找的时候使用跳跃表\n总结 \rRedis底层结构概览\r\n","date":"2021-12-06T01:00:00+08:00","image":"https://cyderx.com/p/redis-data-structure/bg_hu3d03a01dcc18bc5be0e67db3d8d209a6_1082539_120x120_fill_q75_box_smart1.jpg","permalink":"https://cyderx.com/p/redis-data-structure/","title":"Redis底层数据结构"},{"content":"AQS概念 AbstractQueuedSynchronizer是JUC中非常重要的一个同步控制工具\n在JDK的并发包中，我们能看到很多很多的同步器类，比如ReentrantLock（可重入锁）、Semaphore（信号量）和CountDownLatch（倒计时闭锁）等等\n在这些类中，都使用了AbstractQueuedSynchronizer（AQS）来构建\n它们之间的继承关系如下图所示：\n\rAQS的继承关系\r\n可以看出，在基于AQS构建的同步器类中，都继承了AbstractQueuedSynchronizer的子类，而且名字都叫做Sync\n特别地，在ReentrantLock中Sync有两种实现类：NonfairSync和FairSync，分别实现了对不公平锁和公平锁的控制\nAQS的概念，总共有三点：\n 状态信息：我们需要一个整数来保存当前的同步状态信息，这个信息在AbstractQueuedSynchronizer中由int属性state保存。它可以表示任意状态，比如ReentrantLock用它来表示线程已经重复获取锁的次数，Semaphore用它来表示剩余许可的数量 获取（aquire）：获取锁或许可，通常会阻塞，直至状态信息处于可被获取的状态 释放（release）：释放锁或许可，通常不会阻塞，释放操作会唤醒因获取而被阻塞的线程  AQS的内部结构 AQS在类内部维护了一个等待队列，这个队列叫作CLH队列。这个CLH队列实际上是一个双向链表，其示意图如下：\rAQS的等待队列（CLH队列）\r\n CLH队列的优点：\n 先进先出，可以保证公平性 非阻塞的队列，通过自旋锁和CAS保证节点插入和移除的原子性，实现无锁快速插入 采用了自旋锁思想，所以CLH队列也是一种基于链表的可扩展、高性能、公平的自旋锁   再来看一下AQS的UML图：\n\rAQS的UML图\r\n我们会发现：\n  链表的节点就是AQS内部的抽象类Node\n  AQS中的head就是指向队列的head节点，tail指向队列的尾节点\n  Node中有指向前节点的指针（prev）和指向后节点的指针（next），用waiter存放与此节点关联的线程，status则指明了线程的状态\n  可以看出，这个等待队列是存放着被阻塞的线程。在这个等待队列中的线程，会不断地尝试acquire，直到获取到锁或许可，改变状态信息为止\n实际上，AQS内部不只是有一个等待队列，它为各个Condition对象都维护了一个条件等待队列\n图中的ConditionObject就是一个Condition实现类，内部维护了firstWaiter和lastWaiter，指向队列的头和尾\n\rConditionObject类的结构\r\n当线程因为调用Condition类中的await()挂起时，它们会进入条件等待队列中。当它们被signal()或signalAll()唤醒时，会将他们转移到等待队列中，去尝试acquire\n\r等待队列（同步队列）和条件等待队列\r\n因为队列不一样，节点也不一样，因此Node节点派生了3个子类\n SharedNode：共享锁队列的节点 ExclusiveNode：独占锁队列的节点 ConditionNode：条件等待队列的节点  总而言之，AQS的结构如下图所示：\n\rAQS的总体结构\r\n源码分析 让我们从一个简单的非公平ReentrantLock出发，分析AQS在加锁时的表现\nlock() 首先调用ReentrantLock的lock()\npublic void lock() { // 此处是调用了NonFairSync类的lock方法 \t// NonFairSync就是AQS在ReentrantLock中的实现类  sync.lock(); } 进入NonFairSync类的lock方法\n@ReservedStackAccess final void lock() { if (!initialTryLock()) // 首先尝试获取锁，如果没获取到，则进入acquire(1)  // 1为要获取的资源数，因为此处为独占锁，所以数量为1  acquire(1); } // 调用initialTryLock()尝试获取锁 // 这个方法排除了锁重入的情况，接下来的情况都是非重入情况 final boolean initialTryLock() { Thread current = Thread.currentThread(); if (compareAndSetState(0, 1)) { // 使用CAS设置state，尝试获取锁，如果成功，则设置当前线程为owner  setExclusiveOwnerThread(current); return true; } else if (getExclusiveOwnerThread() == current) { // 如果是已经持有锁的线程再次获得锁，则记录重复加锁的数量  int c = getState() + 1; // 如果重入次数发生溢出，则抛异常  if (c \u0026lt; 0) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(c); return true; } else return false; } 进入AbstractQueuedSynchronizer的acquire(int arg)方法\n实际上这个方法是对核心acquire方法的一层简单包装\npublic final void acquire(int arg) { if (!tryAcquire(arg)) // 再次尝试获取锁，若失败则进入核心的线程同步方法acquire()，在这个方法中实现了对队列的管理  acquire(null, arg, false, false, false, 0L); } // 调用tryAcquire方法，再次尝试获取锁 protected final boolean tryAcquire(int acquires) { if (getState() == 0 \u0026amp;\u0026amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } 接下来，我们将进入核心的acquire方法，这是AQS控制线程同步的核心流程，所有使用AQS的工具类最终都会调用此方法\n在分析方法之前，我们先看一下节点有哪些状态（Node的status值）\n// 节点处于等待状态，值为1（且必须为1） static final int WAITING = 1; // 节点被取消调度（被中断或Timeout），这个值必须为负数 static final int CANCELLED = 0x80000000; // 节点处于条件等待队列中 static final int COND = 2; 关于acquire方法，官方文档中写道：\n 循环做以下几件事情：\n​\t检查节点是否为头节点\n​\t如果是，则保证head的稳定性，否则保证有效的前节点\n​\t如果节点是头节点或仍未入队，则尝试获取\n​\t如果节点还未创建，则创建节点\n​\t如果节点未入队，则尝试入队一次\n​\t如果线程从阻塞中被唤醒， 则再次尝试获取（直至指定的自旋时间）\n​\t如果WAITING状态未设置，则设置并重试\n​\t否则，阻塞当前线程，清除WAITING状态并检查是否有异常情况\n 我们可以对照官方文档，理清acquire方法的逻辑\nfinal int acquire(Node node, int arg, boolean shared, boolean interruptible, boolean timed, long time) { Thread current = Thread.currentThread(); // 自旋的时间  byte spins = 0, postSpins = 0; // 中断标记，头节点标记  boolean interrupted = false, first = false; // 在入队时的前一个节点  Node pred = null; // 死循环，不断尝试获取锁  for (;;) { if (!first \u0026amp;\u0026amp; (pred = (node == null) ? null : node.prev) != null \u0026amp;\u0026amp; !(first = (head == pred))) // 节点在队列中，且不是头节点时  if (pred.status \u0026lt; 0) { // 如果前一个节点被取消调度，则调用cleanQueue()方法  // 此方法的作用是反复遍历CLH队列，清除被取消调度的节点，并唤醒正处于等待的节点  cleanQueue(); continue; else if (pred.prev == null) { // 此处的代码笔者暂时也不是很清楚，似乎是节点突然间变成了头节点  // 所以调用onSpinWait()让出CPU使用权，使得头节点稳定下来（不了解）  Thread.onSpinWait(); continue; } } if (first || pred == null) { // 如果节点是头节点，或者还没入队，则尝试获取锁  // 注意，获取锁的顺序并不是严格按照队列的FIFO顺序，未入队的线程也可以尝试获取锁  // 此处就体现了非公平的理念  boolean acquired; try { if (shared) acquired = (tryAcquireShared(arg) \u0026gt;= 0); else acquired = tryAcquire(arg); } catch (Throwable ex) { cancelAcquire(node, interrupted, false); throw ex; } if (acquired) { if (first) { // 如果是头节点获取到锁，则此节点成为新的head  node.prev = null; head = node; pred.next = null; node.waiter = null; if (shared) signalNextIfShared(node); if (interrupted) current.interrupt(); } // 如果成功获取到锁，则返回1，所有获取到锁的线程都会从这里return回去  return 1; } } if (node == null) { // 如果节点仍未创建，则创建节点  if (shared) node = new SharedNode(); else node = new ExclusiveNode(); } else if (pred == null) { // 如果节点未入队，则尝试入队  node.waiter = current; Node t = tail; // 将前一个节点和当前节点联系起来  node.setPrevRelaxed(t); if (t == null) // 如果队列都没创建，则需要创建队列，初始化head  tryInitializeHead(); else if (!casTail(t, node)) // 利用CAS操作更新tail为当前节点  // 如果更新失败，则将当前节点的prev更新成null，在下一次循环中重新进行此操作  node.setPrevRelaxed(null); // back out  else // 更新成功，把原tail的next设置为当前节点  t.next = node; } else if (first \u0026amp;\u0026amp; spins != 0) { // 线程被唤醒之后，在自旋时间内持续尝试获取锁  --spins; // 让出CPU使用权  Thread.onSpinWait(); } else if (node.status == 0) { // 如果节点状态未设置，则设置status为WAITING（1）  node.status = WAITING; } else { long nanos; // 设置自旋时间  spins = postSpins = (byte)((postSpins \u0026lt;\u0026lt; 1) | 1); if (!timed) // 如果没有设置阻塞时间，则阻塞该线程  LockSupport.park(this); else if ((nanos = time - System.nanoTime()) \u0026gt; 0L) // 如果设置了阻塞时间则阻塞指定时间  LockSupport.parkNanos(this, nanos); else break; // 清除状态  node.clearStatus(); // 如果有中断到来，则直接跳出循环  if ((interrupted |= Thread.interrupted()) \u0026amp;\u0026amp; interruptible) break; } } // 跳出循环说明等待被中断了  return cancelAcquire(node, interrupted, interruptible); } 阅读完源码我们可以发现，所有被锁阻塞的线程，都是阻塞在了这个核心的acquire方法中，不断地进行着一个死循环，当获得锁（即CAS改变AQS中的state）时，才能从acquire方法返回，进入到临界区中\n当然，笔者只是给出了一个阅读源码的思路，其中的很多细节，笔者也没有完全搞懂，比如：\n 调用onSpinWait()的意义何在？ byte类型的spins和postSpins变量，究竟有什么作用？ 官方文档中的head的稳定性（ensure head stable），真正的含义是什么？ \u0026hellip;  Doug Lea的代码精妙至极，奈何笔者才疏学浅，疑惑之处甚多，还望各位朋友指点一二\nunlock() 看完了加锁的源码，释放锁的源码就比较简单了，很轻松就能看懂\n首先进入ReentrantLock的unlock方法\npublic void unlock() { // 将AQS的资源释放  sync.release(1); } 接着进入AbstractQueuedSynchronizer的release方法，以释放资源\npublic final boolean release(int arg) { if (tryRelease(arg)) { // 释放资源后，还需唤醒下一个节点  signalNext(head); return true; } return false; } // 尝试释放锁 @ReservedStackAccess protected final boolean tryRelease(int releases) { // 现获取的资源数-要释放的资源数  int c = getState() - releases; // 若释放锁的线程和持有锁的线程不一样，则抛出异常  if (getExclusiveOwnerThread() != Thread.currentThread()) throw new IllegalMonitorStateException(); boolean free = (c == 0); if (free) // free表示资源没有被线程占用  setExclusiveOwnerThread(null); setState(c); return free; } 最后，调用signalNext方法唤醒下一个线程\nprivate static void signalNext(Node h) { Node s; if (h != null \u0026amp;\u0026amp; (s = h.next) != null \u0026amp;\u0026amp; s.status != 0) { // 取消下一个节点的WAITING状态  s.getAndUnsetStatus(WAITING); // 唤醒下一个节点  LockSupport.unpark(s.waiter); } } 总结 AQS作为一个线程同步工具，其核心特点为：\n  维护一个状态量，线程可以获取与释放此状态量，来达到获取锁和释放锁的目的\n  维护一个等待队列（CLH队列），所有未获取到状态量的线程在其中排队，不断地尝试获取状态量\n  对于每一个条件对象（Condition Object），也维护一个条件等待队列，条件达成后，节点将进入正常的等待队列\n  获取锁后，节点被移出队列；释放锁后，节点会唤醒下一个节点\n  ","date":"2021-11-30T01:00:00+08:00","image":"https://cyderx.com/p/abstract-queued-synchronizer/bg_hu3d03a01dcc18bc5be0e67db3d8d209a6_888276_120x120_fill_q75_box_smart1.jpg","permalink":"https://cyderx.com/p/abstract-queued-synchronizer/","title":"AbstractQueuedSynchronizer源码探究"},{"content":"缓存概览 缓存的收益：\n 加速读写，优化用户体验 降低后端负载  缓存的成本：\n 数据可能无法保证一致性 架构复杂度增大 代码维护成本（运维成本）增大  适用场景：\n 开销大的复杂计算 加速请求响应  缓存穿透及优化 缓存穿透：查询一个根本不存在的数据，缓存层和存储层都不会命中\n缓存穿透导致不存在的数据每次请求都要到存储层查询，缓存的保护失去了意义，会使后端存储负载加大\n\r缓存穿透图示\r\n解决办法\n  缓存空对象：存储层不命中后，将空对象保存至缓存层中，之后的访问都会从缓存层获取，这样就保护了后端数据\n缺点：\n 缓存空对象，意味着缓存中存了更多的键，会占用空间，可以通过设置过期时间解决 缓存层和存储层会有一段时间窗口的不一致（比如缓存层中存了空对象并设置过期时间为5分钟，但此时存储层刚好添加了该键对应的数据，就造成了数据不一致），可以使用消息系统或者其他方式解决    布隆过滤器拦截：缓存穿透是查询一个根本不存在的数据，因此可以在缓存层前加一个布隆过滤器，将不存在的数据拦截。\n 关于布隆过滤器，可以查看我写的另一篇文章：布隆过滤器的简单总结\n   \r\n两种解决方式的对比\n   解决方式 适用场景 代价     缓存空对象 数据命中不高、数据变化频繁（实时性高） 需要过多缓存空间、数据不一致   布隆过滤器 数据命中不高，数据相对固定（实时性低） 代码维护复杂    PS：布隆过滤器不适用于数据变化频繁的场景（因为要不停地进行数据的插入和删除，而布隆过滤器对于删除操作极不友好），比较适用于数据相对固定的场景\n缓存击穿及优化 缓存层的某个key承受着非常高的并发，当这个key失效的瞬间，大量的请求会同时击穿缓存，打到DB，就像在纱窗上戳破了一个洞\n\r缓存击穿图示\r\n解决方法\n 设置热点数据不过期，这里的不过期是指物理上的不过期。我们可以设置一个逻辑过期时间，当超过逻辑过期时间时，异步地加载数据，更新缓存。这种方法适用于比较极端的场景（流量特别大），需要承受数据不一致的代价（缓存重构需要时间） 给访问DB操作加上互斥锁，只有一个线程能拿到锁，请求DB并把数据刷到缓存中，其他线程再从缓存拿这个数据  两种解决方法的对比\n   解决方法 优点 缺点     简单分布式锁 思路简单、保证一致性 代码复杂度大、存在死锁和线程池阻塞的风险   热点数据永不过期 杜绝缓存击穿问题 不保证一致性、代码维护成本和内存成本增加    缓存雪崩及优化 缓存层因为某些原因无法提供服务（比如缓存服务器重启，或者大量key在同一时间失效等情况），所有请求都打到存储层，则存储层的调用量会暴增，造成存储层也级联宕机的情况\n\r\n针对两种情况，有不同的解决方法\n 缓存层宕机的解决方法：  保证缓存层服务高可用，例如使用Redis Sentinel或者Redis Cluster 使用隔离组件为后端限流并降级：限制存储层的访问流量（服务限流），并主动停掉一些不太重要的业务，减轻存储层的压力（服务降级）   大量key在同一时间失效的解决方法：  在原有的失效时间基础上增加一个随机值，防止大批key在同一时刻失效 若缓存层是分布式存储，可以将热点数据均匀分布在不同的库中 设置热点数据永不过期（如上文所说，需要承受数据不一致的代价）    ","date":"2021-11-26T10:00:00+08:00","image":"https://cyderx.com/p/cache-problem/bg_hu4ffaf0220a7db3667523ce786184afe1_220850_120x120_fill_q75_box_smart1.jpeg","permalink":"https://cyderx.com/p/cache-problem/","title":"谈谈缓存穿透、击穿和雪崩"},{"content":"布隆过滤器（Bloom Filter）是一个很长的二进制向量和一系列随机映射函数\n用途：判断一个元素是否在一个集合中\n严谨来说，应该是：判断某样东西一定不存在或可能存在\n数据存入  经过K个哈希函数计算，返回K个计算出的hash值 这k个hash值映射到对应的k个数组下标 将二进制向量中这k个下标的对应数据改为1  \r数据存入的过程\r\n数据查询  经过K个哈希函数计算该数据，算出k个hash值 以hash值为下标在二进制向量中找到对应的数据 若有一处的数据为0，则该数据不存在，否则说明数据可能存在（并不是一定存在，有误判的可能）  参数选择 二进制向量的长度会影响误报率，长度越长，误报率越低\n 若长度太小，所有bit都置成1的话，那么查询任何值都会返回“可能存在”，无法起到过滤的目的 若长度太大，则可能会造成空间浪费  哈希函数的个数也会影响误报率，函数个数越多，误报率越低\n 若函数个数太多，则二进制向量置1的速度会变得很快，这样布隆过滤器的效率会变低 若函数个数太少，则误报率变高  参数的选取公式：\n\rm和k的计算公式\r\nk为哈希函数个数，m为布隆过滤器长度，n为插入元素的个数，p为误报率\n总结 优点：\n 占用空间小（存储的是二进制数据） 查询速度快，时间复杂度为O(k) 保密性很好，不存储任何原始数据，只有二进制数据  缺点：\n 存在误判的可能（不同的数据可能映射到二进制向量中的相同位置） 删除困难，也是因为上述的理由  与HashMap的比较：\nHashMap速度也很快，但占用空间太大，因为有负载因子的存在，为了避免哈希冲突，空间是没办法用满的，会造成大量的空间浪费。使用布隆过滤器可以在不牺牲查找速度的同时，降低空间消耗，代价就是判断并不完全准确\n应用场景：\n URL黑名单过滤 解决缓存穿透的问题 \u0026hellip;  ","date":"2021-11-26T08:00:00+08:00","image":"https://cyderx.com/p/bloom-filter/bg_hu1cee95830531cbd4ff92afca563f6bce_71782_120x120_fill_q75_box_smart1.jpeg","permalink":"https://cyderx.com/p/bloom-filter/","title":"布隆过滤器的简单总结"},{"content":"简介 ConcurrentLinkedQueue是高并发环境中性能最好的队列\n要想队列保证线程安全，有两种实现方式\n 阻塞算法：锁 非阻塞算法：循环CAS  在队列中，BlockingQueue是阻塞算法的典型实现（使用锁来保证线程安全），而ConcurrentLinkedQueue则是非阻塞算法的典型实现（使用CAS保证线程安全）\n原理 \rConcurrentLinkedQueue的基本结构\r\nNode节点\nstatic final class Node\u0026lt;E\u0026gt; { volatile E item; volatile Node\u0026lt;E\u0026gt; next; // 利用CAS操作向后添加一个节点  void appendRelaxed(Node\u0026lt;E\u0026gt; next) { NEXT.set(this, next); } // 利用CAS操作设置值（cmp是期望值，val是要设置的值）  boolean casItem(E cmp, E val) { return ITEM.compareAndSet(this, cmp, val); } } head和tail\ntransient volatile Node\u0026lt;E\u0026gt; head; private transient volatile Node\u0026lt;E\u0026gt; tail; // 初始时，head和tail都指向一个空节点 public ConcurrentLinkedQueue() { head = tail = new Node\u0026lt;E\u0026gt;(); } CoucurrentLinkedQueue规定了如下几个不变性：\n 最后一个元素的next为null 队列中所有未删除的节点的item都不能为null，且都能从head节点遍历到 对于要删除的节点，不是直接将其设置为null，而是先将其item域设置为null（迭代器会跳过item为null的节点） head和tail并不一定指向真正的头和尾节点，因为它们的更新有滞后性，每次更新会跳跃两个元素  入队 \r入队过程\r\npublic boolean offer(E e) { // 确保值不为空，且创建新节点  final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;E\u0026gt;(Objects.requireNonNull(e)); // 循环进行CAS操作，直至成功为止（因为CAS操作有可能失败）  // t：指向tail  // p、q：进行遍历使用的指针，p在前，q在后  for (Node\u0026lt;E\u0026gt; t = tail, p = t;;) { Node\u0026lt;E\u0026gt; q = p.next; if (q == null) { // p是最后一个节点的情况，此时q为null  if (NEXT.compareAndSet(p, null, newNode)) { // 将新创建的节点添加到链表末尾  if (p != t) // 当p和t不相等，也就是新创建的节点和原tail中间隔着一个元素时，才更新tail，相当于tail的1次更新跨越2个元素  TAIL.weakCompareAndSet(this, t, newNode); return true; } // CAS失败，再次尝试  } else if (p == q) // 遇到了哨兵节点，从head开始重新遍历，或者如果有其他线程修改了tail，就使用这个刚被修改的tail  // t != (t = tail)是为了检查在执行过程中，tail是否被其他线程修改，如果是，则进行一次“打赌”，将刚被修改的tail当作链表末尾  // 这样就可以提高性能，省去了重新查找tail的开销  p = (t != (t = tail)) ? t : head; else // p不是最后一个节点的情况（添加了节点，tail未更新的情况）  // 将p不断推进到链表末尾  p = (p != t \u0026amp;\u0026amp; t != (t = tail)) ? t : q; } }  在JDK 1.7的实现中，doug lea使用hops变量来控制并减少tail节点的更新频率，并不是每次节点入队后都将 tail节点更新成尾节点，而是当tail节点和尾节点的距离大于等于常量HOPS的值（默认等于1）时才更新tail节点，tail和尾节点的距离越长使用CAS更新tail节点的次数就会越少，但是距离越长带来的负面效果就是每次入队时定位尾节点的时间就越长，因为循环体需要多循环一次来定位出尾节点，但是这样仍然能提高入队的效率，因为从本质上来看它通过增加对volatile变量的读操作来减少了对volatile变量的写操作，而对volatile变量的写操作开销要远远大于读操作，所以入队效率会有所提升。\n在JDK 1.8的实现中，tail的更新时机是通过p和t是否相等来判断的，其实现结果和JDK 1.7相同，即当tail节点和尾节点的距离大于等于1时，更新tail。\n 出队 \r出队过程\r\npublic E poll() { // 循环进行CAS操作  restartFromHead: for (;;) { for (Node\u0026lt;E\u0026gt; h = head, p = h, q;; p = q) { final E item; if ((item = p.item) != null \u0026amp;\u0026amp; p.casItem(item, null)) { // p的item值不为null，说明是有效节点，并使用CAS将p的item置为null  if (p != h) // head的1次更新会跨越2个元素（当head指向的节点中元素为null，才更新head）  // 更新head的同时，原先的head成为哨兵节点（next指向自己的节点）  updateHead(h, ((q = p.next) != null) ? q : p); return item; } else if ((q = p.next) == null) { // 链表为空，则更新head，并返回null  updateHead(h, p); return null; } else if (p == q) // 遇到哨兵节点，重新从head开始遍历  continue restartFromHead; } } } 总结  使用CAS原子指令处理对数据的并发访问 head和tail并非总是指向队列的头和尾节点，也就是说允许队列处于不一致状态。这个特性把入队、出队时，原本需要一起原子化执行的两个步骤分离开来，缩小了入队、出队时需要原子化更新值的范围到唯一变量，而head和tail的更新使用批处理的方式完成（一次更新2步）。这样的做法减少了入队、出队操作的开销，提高了入队、出队的性能 因为队列有时会处于不一致状态，所以ConcurrentLinkedQueue 使用三个不变式来维护非阻塞算法的正确性  ","date":"2021-11-26T01:00:00+08:00","image":"https://cyderx.com/p/concurrent-linked-queue/CLQ_hu3d03a01dcc18bc5be0e67db3d8d209a6_166172_120x120_fill_q75_box_smart1.jpg","permalink":"https://cyderx.com/p/concurrent-linked-queue/","title":"ConcurrentLinkedQueue源码分析"}]