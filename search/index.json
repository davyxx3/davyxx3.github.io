[{"content":"缓存穿透及优化 缓存穿透：查询一个根本不存在的数据，缓存层和存储层都不会命中\n缓存穿透导致不存在的数据每次请求都要到存储层查询，缓存的保护失去了意义，会使后端存储负载加大\n\r缓存穿透图示\r\n解决办法\n  缓存空对象：存储层不命中后，将空对象保存至缓存层中，之后的访问都会从缓存层获取，这样就保护了后端数据\n缺点：\n 缓存空对象，意味着缓存中存了更多的键，会占用空间，可以通过设置过期时间解决 缓存层和存储层会有一段时间窗口的不一致（比如缓存层中存了空对象并设置过期时间为5分钟，但此时存储层刚好添加了该键对应的数据，就造成了数据不一致），可以使用消息系统或者其他方式解决    布隆过滤器拦截：缓存穿透是查询一个根本不存在的数据，因此可以在缓存层前加一个布隆过滤器，将不存在的数据拦截。\n 关于布隆过滤器，可以查看我写的另一篇文章：布隆过滤器的简单总结\n   \r\n两种解决方式的对比\n   解决方式 适用场景 代价     缓存空对象 数据命中不高、数据变化频繁（实时性高） 需要过多缓存空间、数据不一致   布隆过滤器 数据命中不高，数据相对固定（实时性低） 代码维护复杂    PS：布隆过滤器不适用于数据变化频繁的场景（因为要不停地进行数据的插入和删除，而布隆过滤器对于删除操作极不友好），比较适用于数据相对固定的场景\n缓存击穿及其优化 缓存层的某个key承受着非常高的并发，当这个key失效的瞬间，大量的请求会同时击穿缓存，打到DB，就像在纱窗上戳破了一个洞\n\r缓存击穿图示\r\n解决方法\n 设置热点数据不过期，这里的不过期是指物理上的不过期。我们可以设置一个逻辑过期时间，当超过逻辑过期时间时，异步地加载数据，更新缓存。这种方法适用于比较极端的场景（流量特别大），需要承受数据不一致的代价（缓存重构需要时间） 给访问DB操作加上互斥锁，只有一个线程能拿到锁，请求DB并把数据刷到缓存中，其他线程再从缓存拿这个数据  两种解决方法的对比\n   解决方法 优点 缺点     简单分布式锁 思路简单、保证一致性 代码复杂度大、存在死锁和线程池阻塞的风险   热点数据永不过期 杜绝缓存击穿问题 不保证一致性、代码维护成本和内存成本增加    缓存雪崩及优化 缓存层因为某些原因无法提供服务（比如缓存服务器重启，或者大量key在同一时间失效等情况），所有请求都打到存储层，则存储层的调用量会暴增，造成存储层也级联宕机的情况\n\r\n针对两种情况，有不同的解决方法\n 缓存层宕机的解决方法：  保证缓存层服务高可用，例如使用Redis Sentinel或者Redis Cluster 使用隔离组件为后端限流并降级：限制存储层的访问流量（服务限流），并主动停掉一些不太重要的业务，减轻存储层的压力（服务降级）   大量key在同一时间失效的解决方法：  在原有的失效时间基础上增加一个随机值，防止大批key在同一时刻失效 若缓存层是分布式存储，可以将热点数据均匀分布在不同的库中 设置热点数据永不过期（如上文所说，需要承受数据不一致的代价）    ","date":"2021-11-26T10:00:00+08:00","image":"https://davyxx3.github.io/p/%E8%B0%88%E8%B0%88%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%87%BB%E7%A9%BF%E5%92%8C%E9%9B%AA%E5%B4%A9/bg_hu4ffaf0220a7db3667523ce786184afe1_220850_120x120_fill_q75_box_smart1.jpeg","permalink":"https://davyxx3.github.io/p/%E8%B0%88%E8%B0%88%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%87%BB%E7%A9%BF%E5%92%8C%E9%9B%AA%E5%B4%A9/","title":"谈谈缓存穿透、击穿和雪崩"},{"content":"布隆过滤器（Bloom Filter）是一个很长的二进制向量和一系列随机映射函数\n用途：判断一个元素是否在一个集合中\n严谨来说，应该是：判断某样东西一定不存在或可能存在\n数据存入  经过K个哈希函数计算，返回K个计算出的hash值 这k个hash值映射到对应的k个数组下标 将二进制向量中这k个下标的对应数据改为1  \r数据存入的过程\r\n数据查询  经过K个哈希函数计算该数据，算出k个hash值 以hash值为下标在二进制向量中找到对应的数据 若有一处的数据为0，则该数据不存在，否则说明数据可能存在（并不是一定存在，有误判的可能）  参数选择 二进制向量的长度会影响误报率，长度越长，误报率越低\n 若长度太小，所有bit都置成1的话，那么查询任何值都会返回“可能存在”，无法起到过滤的目的 若长度太大，则可能会造成空间浪费  哈希函数的个数也会影响误报率，函数个数越多，误报率越低\n 若函数个数太多，则二进制向量置1的速度会变得很快，这样布隆过滤器的效率会变低 若函数个数太少，则误报率变高  参数的选取公式：\n\rm和k的计算公式\r\nk为哈希函数个数，m为布隆过滤器长度，n为插入元素的个数，p为误报率\n总结 优点：\n 占用空间小（存储的是二进制数据） 查询速度快，时间复杂度为O(k) 保密性很好，不存储任何原始数据，只有二进制数据  缺点：\n 存在误判的可能（不同的数据可能映射到二进制向量中的相同位置） 删除困难，也是因为上述的理由  与HashMap的比较：\nHashMap速度也很快，但占用空间太大，因为有负载因子的存在，为了避免哈希冲突，空间是没办法用满的，会造成大量的空间浪费。使用布隆过滤器可以在不牺牲查找速度的同时，降低空间消耗，代价就是判断并不完全准确\n应用场景：\n URL黑名单过滤 解决缓存穿透的问题 \u0026hellip;  ","date":"2021-11-26T08:00:00+08:00","image":"https://davyxx3.github.io/p/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93/bg_hu1cee95830531cbd4ff92afca563f6bce_71782_120x120_fill_q75_box_smart1.jpeg","permalink":"https://davyxx3.github.io/p/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93/","title":"布隆过滤器的简单总结"},{"content":"简介 ConcurrentLinkedQueue是高并发环境中性能最好的队列\n要想队列保证线程安全，有两种实现方式\n 阻塞算法：锁 非阻塞算法：循环CAS  在队列中，BlockingQueue是阻塞算法的典型实现（使用锁来保证线程安全），而ConcurrentLinkedQueue则是非阻塞算法的典型实现（使用CAS保证线程安全）\n原理 \rConcurrentLinkedQueue的基本结构\r\nNode节点\nstatic final class Node\u0026lt;E\u0026gt; { volatile E item; volatile Node\u0026lt;E\u0026gt; next; // 利用CAS操作向后添加一个节点  void appendRelaxed(Node\u0026lt;E\u0026gt; next) { NEXT.set(this, next); } // 利用CAS操作设置值（cmp是期望值，val是要设置的值）  boolean casItem(E cmp, E val) { return ITEM.compareAndSet(this, cmp, val); } } head和tail\ntransient volatile Node\u0026lt;E\u0026gt; head; private transient volatile Node\u0026lt;E\u0026gt; tail; // 初始时，head和tail都指向一个空节点 public ConcurrentLinkedQueue() { head = tail = new Node\u0026lt;E\u0026gt;(); } CoucurrentLinkedQueue规定了如下几个不变性：\n 最后一个元素的next为null 队列中所有未删除的节点的item都不能为null，且都能从head节点遍历到 对于要删除的节点，不是直接将其设置为null，而是先将其item域设置为null（迭代器会跳过item为null的节点） head和tail并不一定指向真正的头和尾节点，因为它们的更新有滞后性，每次更新会跳跃两个元素  入队 \r入队过程\r\npublic boolean offer(E e) { // 确保值不为空，且创建新节点  final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;E\u0026gt;(Objects.requireNonNull(e)); // 循环进行CAS操作，直至成功为止（因为CAS操作有可能失败）  // t：指向tail  // p、q：进行遍历使用的指针，p在前，q在后  for (Node\u0026lt;E\u0026gt; t = tail, p = t;;) { Node\u0026lt;E\u0026gt; q = p.next; if (q == null) { // p是最后一个节点的情况，此时q为null  if (NEXT.compareAndSet(p, null, newNode)) { // 将新创建的节点添加到链表末尾  if (p != t) // 当p和t不相等，也就是新创建的节点和原tail中间隔着一个元素时，才更新tail，相当于tail的1次更新跨越2个元素  TAIL.weakCompareAndSet(this, t, newNode); return true; } // CAS失败，再次尝试  } else if (p == q) // 遇到了哨兵节点，从head开始重新遍历，或者如果有其他线程修改了tail，就使用这个刚被修改的tail  // t != (t = tail)是为了检查在执行过程中，tail是否被其他线程修改，如果是，则进行一次“打赌”，将刚被修改的tail当作链表末尾  // 这样就可以提高性能，省去了重新查找tail的开销  p = (t != (t = tail)) ? t : head; else // p不是最后一个节点的情况（添加了节点，tail未更新的情况）  // 将p不断推进到链表末尾  p = (p != t \u0026amp;\u0026amp; t != (t = tail)) ? t : q; } }  在JDK 1.7的实现中，doug lea使用hops变量来控制并减少tail节点的更新频率，并不是每次节点入队后都将 tail节点更新成尾节点，而是当tail节点和尾节点的距离大于等于常量HOPS的值（默认等于1）时才更新tail节点，tail和尾节点的距离越长使用CAS更新tail节点的次数就会越少，但是距离越长带来的负面效果就是每次入队时定位尾节点的时间就越长，因为循环体需要多循环一次来定位出尾节点，但是这样仍然能提高入队的效率，因为从本质上来看它通过增加对volatile变量的读操作来减少了对volatile变量的写操作，而对volatile变量的写操作开销要远远大于读操作，所以入队效率会有所提升。\n在JDK 1.8的实现中，tail的更新时机是通过p和t是否相等来判断的，其实现结果和JDK 1.7相同，即当tail节点和尾节点的距离大于等于1时，更新tail。\n 出队 \r出队过程\r\npublic E poll() { // 循环进行CAS操作  restartFromHead: for (;;) { for (Node\u0026lt;E\u0026gt; h = head, p = h, q;; p = q) { final E item; if ((item = p.item) != null \u0026amp;\u0026amp; p.casItem(item, null)) { // p的item值不为null，说明是有效节点，并使用CAS将p的item置为null  if (p != h) // head的1次更新会跨越2个元素（当head指向的节点中元素为null，才更新head）  // 更新head的同时，原先的head成为哨兵节点（next指向自己的节点）  updateHead(h, ((q = p.next) != null) ? q : p); return item; } else if ((q = p.next) == null) { // 链表为空，则更新head，并返回null  updateHead(h, p); return null; } else if (p == q) // 遇到哨兵节点，重新从head开始遍历  continue restartFromHead; } } } 总结  使用CAS原子指令处理对数据的并发访问 head和tail并非总是指向队列的头和尾节点，也就是说允许队列处于不一致状态。这个特性把入队、出队时，原本需要一起原子化执行的两个步骤分离开来，缩小了入队、出队时需要原子化更新值的范围到唯一变量，而head和tail的更新使用批处理的方式完成（一次更新2步）。这样的做法减少了入队、出队操作的开销，提高了入队、出队的性能 因为队列有时会处于不一致状态，所以ConcurrentLinkedQueue 使用三个不变式来维护非阻塞算法的正确性  ","date":"2021-11-26T01:00:00+08:00","image":"https://davyxx3.github.io/p/concurrentlinkedqueue%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/CLQ_hu3d03a01dcc18bc5be0e67db3d8d209a6_166172_120x120_fill_q75_box_smart1.jpg","permalink":"https://davyxx3.github.io/p/concurrentlinkedqueue%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","title":"ConcurrentLinkedQueue源码分析"}]